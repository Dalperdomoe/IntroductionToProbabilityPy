{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 8: Joint Distributions\n",
    " \n",
    "This Jupyter notebook is the Python equivalent of the R code in section 8.8 R, pp. 373 - 375, [Introduction to Probability, 1st Edition](https://www.crcpress.com/Introduction-to-Probability/Blitzstein-Hwang/p/book/9781466575578), Blitzstein & Hwang.\n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Beta and Gamma distributions\n",
    "\n",
    "The Beta and Gamma distributions are programmed into R.\n",
    "\n",
    "* dbeta, pbeta, rbeta: To evaluate the $Beta(a, b)$ PDF or CDF at $x$, we use dbeta(x,a,b) and pbeta(x,a,b). To generate n realizations from the $Beta(a, b)$ distribution, we use rbeta(n,a,b). \n",
    "* dgamma, pgamma, rgamma: To evaluate the $Gamma(a, \\lambda)$ PDF or CDF at $x$, we use dgamma(x,a,lambda) or pgamma(x,a,lambda). To generate n realizations from the $Gamma(a, \\lambda)$ distribution, we use rgamma(n,a,lambda). \n",
    "\n",
    "For example, we can check that the $Gamma(3, 2)$ distribution has mean $\\frac{3}{2}$ and variance $\\frac{3}{4}$. To do this, we generate a large number of $Gamma(3, 2)$ random variables using rgamma, then compute their mean and var:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "y <- rgamma(10^5,3,2)\n",
    "mean(y)\n",
    "var(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Did you get values that were close to 1.5 and 0.75, respectively?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convoluton of Uniforms\n",
    "\n",
    "Using R, we can quickly verify that for $X, Y \\stackrel{i.i.d.}{\\sim} Unif(0, 1)$, the distribution of $T = X + Y$ is triangular in shape:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "x <- runif(10^5)\n",
    "y <- runif(10^5)\n",
    "hist(x+y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The histogram looks like an ascending and then descending staircase, a discrete approximation to a triangle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayes ' billiards\n",
    "\n",
    "In the Bayes' billiards story, we have $n$ white balls and 1 gray ball, throw them onto the unit interval completely at random, and count the number of white balls to the left of the gray ball. Letting $p$ be the position of the gray ball and $X$ be the number of white balls to the left of the gray ball, we have\n",
    "\n",
    "\\begin{align}\n",
    "  p &\\sim Unif(0, 1) \\\\\n",
    "  X|p &\\sim Bin(n, p)\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By performing this experiment a large number of times, we can verify the results we derived in this chapter about the marginal PMF of $X$ and the posterior PDF of $p given X = x$. We'll let the number of simulations be called `nsim`, to avoid a name conflict with the number of white balls, `n`, which we set equal to 10:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "nsim <- 10^5\n",
    "n <- 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We simulate 105 values of p, then simulate 105 values from the conditional distribution of X given p:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "p <- runif(nsim)\n",
    "x <- rbinom(nsim,n,p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that we feed the entire vector p into rbinom. This means that the first element of x is generated using the first element of p, the second element of x is generated using the second element of p, and so forth. Thus, conditional on a particular element of p, the corresponding element of x is Binomial, but the elements of p are themselves Uniform, exactly as the model specifies.\n",
    "\n",
    "According to the Bayes’ billiards argument, the marginal distribution of X should be Discrete Uniform on the integers 0 through n. Is this in fact the case? We can make a histogram of x to check! Because the distribution of X is discrete, we tell R to make the histogram breaks at −0.5, 0.5, 1.5,... so that each bar is centered at an integer value:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "hist(x,breaks=seq(-0.5,n+0.5,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indeed, all the histogram bars are approximately equal in height, consistent with a Discrete Uniform distribution. \n",
    "\n",
    "Now for the posterior distribution of p given $X = x$. Conditioning is very simple in R. To consider only the simulated values of p where the value of $X$ was 3, we use square brackets, like this: $p[x==3]$. In particular, we can create a histogram of these values to see what the posterior distribution of p given X = 3 looks like; try hist(p[x==3]).\n",
    "\n",
    "According to the Beta-Binomial conjugacy result, the true posterior distribution is $p|X = 3 \\sim Beta(4, 8)$. We can plot the histogram of p[x==3] next to a histogram of simulated values from the $Beta(4, 8)$ distribution to confirm that they look similar:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "par(mfrow=c(1,2))\n",
    "hist(p[x==3])\n",
    "hist(rbeta(10^4,4,8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first line tells R we want two side-by-side plots, and the second and third lines create the histograms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulating order statistics\n",
    "\n",
    "Simulating order statistics in R is easy: we simply simulate i.i.d. r.v.s and use sort to sort them in order. For example,"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "sort(rnorm(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "produces one realization of $X_{(1)}, \\dots, X_{(10)}$, where $X_{(1)}, \\dots, X_{(10)}$ are i.i.d. $N(0, 1)$. If we want to plot a histogram of realizations of, say, $X_{(9)}$, we'll need to use replicate:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "order_stats <- replicate(10^4, sort(rnorm(10)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This creates a matrix, order_stats, with 10 rows. The ith row of the matrix contains 10<sup>4</sup> realizations of $X(i)$. Now we can create a histogram of $X(9)$, simply by selecting row 9 of the matrix:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "x9 <- order_stats[9,]\n",
    "hist(x9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also compute summaries like mean(x9) and var(x9)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "&copy; Blitzstein, Joseph K.; Hwang, Jessica. Introduction to Probability (Chapman & Hall/CRC Texts in Statistical Science)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
