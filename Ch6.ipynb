{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 6: Moments\n",
    " \n",
    "This Jupyter notebook is the Python equivalent of the R code in section 6.9 R, [Introduction to Probability, 1st Edition](https://www.crcpress.com/Introduction-to-Probability/Blitzstein-Hwang/p/book/9781466575578), Blitzstein & Hwang.\n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions\n",
    "\n",
    "The MGF of an r.v. is a _function_. As an example of defining and working with functions in Python, let's use the $N(0, 1)$ MGF, which is given by $M(t) = e^{\\frac{t^{2}}{2}}$. The code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calling function M with a single value: \n",
      "M(0) = 1.0\n",
      "\n",
      "calling M with a vector: \n",
      "M(np.arange(1,11))) = [  1.64872127e+00   7.38905610e+00   9.00171313e+01   2.98095799e+03\n",
      "   2.68337287e+05   6.56599691e+07   4.36731791e+10   7.89629602e+13\n",
      "   3.88084696e+17   5.18470553e+21]\n"
     ]
    }
   ],
   "source": [
    "def M(t):\n",
    "    return np.exp(t**2/2)\n",
    "\n",
    "print('calling function M with a single value: \\nM(0) = {}\\n'.format(M(0)))\n",
    "\n",
    "print('calling M with a vector: \\nM(np.arange(1,11))) = {}'.format(M(np.arange(1,11))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "defines `M` to be this function. The `def` Python keyword says that we're [defining a function](https://docs.python.org/3/tutorial/controlflow.html#defining-functions). The function is named `M`, and it takes one variable `t` (called the argument or parameter of the function). The line declaring the function name and list of parameter(s) is terminated with a colon `:`, with the body of the function following on the next line after an indent. Note that a simple Python function will not be able to flexibly deal with both single or vector inputs, such as is possible with a function in R. However, since our function `M` relies on [`numpy.exp`](https://docs.scipy.org/doc/numpy/reference/generated/numpy.exp.html), `M` can accept both a nested sequence of objects or `numpy` arrays as inputs, and return an single or tuple of `numpy` array as output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Writing\n",
    "\n",
    "    def M(x):\n",
    "        return np.exp(x**2/2)\n",
    "\n",
    "would define the same function `M`, except that now the argument is named `x`. Giving the arguments names is helpful for functions of more than one variable, since Python then saves us from having to remember the order in which to write the arguments, and allows us to assign default values. For example, the $N(\\mu, \\sigma^2)$ MGF is given by $g(t) = exp\\left(\\mu \\, t + \\frac{\\sigma^2 \\, t^2}{2} \\right)$, which depends on $t$, $mu$, and $\\sigma$. We can define this in Python by"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N(2, 3) MGF evaluated at 1 = 665.1416330443618\n"
     ]
    }
   ],
   "source": [
    "def g(t, mean=0, sd=1):\n",
    "    return np.exp(mean*t + (sd**2 * t**2)/2)\n",
    "\n",
    "print('N(2, 3) MGF evaluated at 1 = {}'.format(g(1, 2, 3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is `g(1, 2, 3)`? It's the $N(2, 3^{2})$ MGF evaluated at 1, but it may be hard to remember which argument is which, especially when working with many functions with many arguments over the course of many months. So we can also write `g(1, mean=2, sd=3)` or `g(1, sd=3, mean=2)`. Since the `mean` and `sd` function parameters have the form `parameter = expression`, the function is said to have \"default parameter values.\"\n",
    "\n",
    "Also, when defining `g` we specified default values of 0 for the mean and 1 for the standard deviation, so if we want the $N(0, 5^2)$ MGF evaluated at 3, we can use `g(3, sd=5)` as shorthand. It would be bad here to write `g(3, 5)`, since that is ambiguous about which argument is omitted; in fact, Python interprets this as `g(t3, mean=5)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "g(1, mean=2, sd=3) = 665.1416330443618\t... explicitly using parameter names\n",
      "g(3, 5) = 294267566.0415088\t\t... which parameter is omitted?\n",
      "g(3, mean=5) = 294267566.0415088\t... 'mean' parameter was omitted\n"
     ]
    }
   ],
   "source": [
    "print('g(1, mean=2, sd=3) = {}\\t... explicitly using parameter names'.format(g(1, mean=2, sd=3)))\n",
    "\n",
    "print('g(3, 5) = {}\\t\\t... which parameter is omitted?'.format(g(3, 5)))\n",
    "\n",
    "print('g(3, mean=5) = {}\\t... \\'mean\\' parameter was omitted'.format(g(3, mean=5)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Moments\n",
    "\n",
    "LOTUS makes it easy to write down any moment of a continuous r.v. as an integral. The [`scipy.integrate`](https://docs.scipy.org/doc/scipy/reference/tutorial/integrate.html) module in SciPy can help us do the integral numerically, using the [`scipy.integrate.quad`](https://docs.scipy.org/doc/scipy/reference/generated/scipy.integrate.quad.html#scipy.integrate.quad) function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.integrate import quad\n",
    "\n",
    "#print(quad.__doc__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, let's approximate the 6<sup>th</sup> moment of a $N(0, 1)$ r.v. The code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6th moment of N(0,1) = 15.000000000000004, with error = 4.4229319318339374e-09\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import norm\n",
    "\n",
    "def g(x):\n",
    "    return x**6 * norm.pdf(x)\n",
    "\n",
    "y, abserr = quad(g, -np.inf, np.inf)\n",
    "print('6th moment of N(0,1) = {}, with error = {}'.format(y, abserr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "asks `quad` to compute $\\int_{-\\infty}^{\\infty} g(x) \\, dx$, where $g(x) = x^6 \\, \\phi(x)$ with $\\phi$ the $N(0, 1)$ PDF. When we ran this, `quad` reported 15 (the correct answer, as we know from this chapter!) and that the absolute error was less than 4.423 $\\times$ 10<sup>−9</sup>. \n",
    "\n",
    "However, all of the continuous distributions supported in [`scipy.stats`](https://docs.scipy.org/doc/scipy/reference/tutorial/stats/continuous.html#moments) have a `moment(n, loc=0, scale=1)` function that allows you to quickly and easily obtain the n<sup>th</sup> order non-central moment of the continuous distribution in question. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scipy.stats.norm.moment(n=6) = 15.00000000089533\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import moment\n",
    "\n",
    "#print(moment.__doc__)\n",
    "\n",
    "print('scipy.stats.norm.moment(n=6) = {}'.format(norm.moment(n=6)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, to check that the 2<sup>nd</sup> moment (and variance) of a $Unif(−1, 1)$ r.v. is 1/3, we can use `quad` again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2nd moment of Unif(-1,1) = 0.3333333333333333, with error = 3.700743415417188e-15\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import uniform\n",
    "\n",
    "def h(x):\n",
    "    \"\"\" scipy.stats.uniform is constant between\n",
    "            a = loc\n",
    "            b = loc + scale\n",
    "    \"\"\"\n",
    "    a = -1\n",
    "    b = 1\n",
    "    loc = a\n",
    "    scale = b - loc\n",
    "    return x**2 * uniform.pdf(x, loc=loc, scale=scale)\n",
    "\n",
    "y, abserr = quad(h, -1, 1)\n",
    "print('2nd moment of Unif(-1,1) = {}, with error = {}'.format(y, abserr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#x2623; 6.9.1. Numerical integration runs into difficulties for some functions; as usual, checking answers in multiple ways is a good idea. Using `numpy.inf` for parameter `b` (the upper limit of integration) is preferred to using a large number as the upper limit when integrating up to $\\infty$ (and likewise for a lower limit of `a = -numpy.inf` for $-\\infty$. For example, on many systems `quad(norm.pdf, 0, 10**6)` reports 0.0 while `quad(norm.pdf, 0, numpy.inf)` reports the correct answer, 0.5."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternately, we can either use `moment(n=2, loc=-1, scale=2)` or just `var(loc=-1, scale=2)`, keeping in mind that `loc=-1` and `scale = interval length = 2`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uniform.moment(n=2, loc=-1, scale=2) = 0.33333333333333326\n",
      "uniform.var(loc=-1, scale=2) = 0.3333333333333333\n"
     ]
    }
   ],
   "source": [
    "print('uniform.moment(n=2, loc=-1, scale=2) = {}'.format(uniform.moment(n=2, loc=-1, scale=2)))\n",
    "\n",
    "print('uniform.var(loc=-1, scale=2) = {}'.format(uniform.var(loc=-1, scale=2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For moments of a discrete r.v., we can use LOTUS and the `numpy.sum` function. For example, to find the 2<sup>nd</sup> moment of $X \\sim Pois(7)$, we can use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2nd moment of Pois(7) = 55.99999999999994\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import poisson\n",
    "\n",
    "def g(k):\n",
    "    return k**2 * poisson.pmf(k, 7)\n",
    "\n",
    "# we want to sum up to and including 100, so the upper limit is 100+1\n",
    "ans = np.sum(g(np.arange(0, 100+1)))\n",
    "print('2nd moment of Pois(7) = {}'.format(ans))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we summed up to 100 since it’s clear after getting a sense of the terms that the total contribution of all the terms after k = 100 is negligible (choosing an upper limit in this way is in contrast to how to use the integrate command in the continuous case). The result is extremely close to 56, which is comforting since $E(X^{2}) = Var(X) + (EX)^{2} = 7 + 49 = 56$.\n",
    "\n",
    "But similar to continous r.v., the [discrete r.v. in `scipy.stats`](https://docs.scipy.org/doc/scipy/reference/tutorial/stats/discrete.html#moments) have a `moment` function as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "poisson.moment(n=2, mu=7) = 56\n"
     ]
    }
   ],
   "source": [
    "print('poisson.moment(n=2, mu=7) = {}'.format(poisson.moment(n=2, mu=7)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A sample moment can be found in easily using Numpy. If `x` is a vector of data, then [`numpy.mean(x)`](https://docs.scipy.org/doc/numpy-1.15.1/reference/generated/numpy.mean.html) gives its sample mean and, more generally, `numpy.mean(x**n)` gives the n<sup>th</sup> sample mean for any positive integer `n`. For example,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17.0336574808\n"
     ]
    }
   ],
   "source": [
    "# seed the random number generator\n",
    "np.random.seed(123)\n",
    "\n",
    "x = norm.rvs(size=100)\n",
    "print(np.mean(x**6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "gives the 6<sup>th</sup> sample moment of 100 i.i.d.  $N(0, 1)$ r.v.s. How close is it to the true 6<sup>th</sup> moment? How close are other sample moments to the corresponding true moments?\n",
    "\n",
    "The sample variance can also be found in easily with Numpy. If `x` is a vector of data, then using the `ddof` parameter (delta degrees of freedom) such as in [`numpy.var(x, ddof=1)`](https://docs.scipy.org/doc/numpy/reference/generated/numpy.var.html) gives its sample variance. This returns `nan` (not a number) as well as issuing `RuntimeWarning: Degrees of freedom <= 0 for slice` (the divisor used in the calculation is `len(x) - ddof`) if `x` has length 1, since the $n − 1$ in the denominator is 0 in this case. It makes sense not to return a numerical value in this case, not only because of the definition but also because it would be insane to try to estimate the variability of a population if we only have one observation!\n",
    "\n",
    "For a simple demonstration of using the sample mean and sample variance to estimate the true mean and true variance of a distribution, we generate 1000 times from a $N(0, 1)$ distribution and store the values in `z`. We then compute the sample mean and sample variance with `numpy.mean(z)` and `numpy.var(z, ddof=1)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample mean of z: -0.03956413608079184\n",
      "sample variance of z: 1.0025782735213273\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(123)\n",
    "z = norm.rvs(size=1000)\n",
    "\n",
    "print('sample mean of z: {}'.format(np.mean(z)))\n",
    "print('sample variance of z: {}'.format(np.var(z, ddof=1)))\n",
    "\n",
    "with open('z.txt', 'w') as f:\n",
    "    for e in z:\n",
    "        f.write('{}\\n'.format(e))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We find that `numpy.mean(z)` is close to 0 and `numpy.var(z, ddof=1)` is close to 1. You can try this out for a $N(\\mu, \\sigma^2)$ distribution (or other distribution) of your choosing; just remember that `numpy.norm.rvs` takes $\\sigma$ as the `scale` parameter, and not $\\sigma^2$!\n",
    "\n",
    "The sample standard deviation of `x` can be found using [`numpy.std(x, ddof=1)`](https://docs.scipy.org/doc/numpy/reference/generated/numpy.std.html). This gives the same result as `numpy.sqrt(numpy.var(x, ddof=1))`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "np.std(z, ddof=1) = 1.001288306893338\n",
      "np.sqrt(np.var(z, ddof=1)) = 1.001288306893338\n"
     ]
    }
   ],
   "source": [
    "print('np.std(z, ddof=1) = {}'.format(np.std(z, ddof=1)))\n",
    "\n",
    "print('np.sqrt(np.var(z, ddof=1)) = {}'.format(np.sqrt(np.var(z, ddof=1))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While the [`scipy.stats`](https://docs.scipy.org/doc/scipy/reference/stats.html) module does have functions for [`skew`](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.skew.html) and [`kurtosis`](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.kurtosis.html), both functions rely on the _population standard deviation_ (with $n$ rather than $n-1$ in the denominator).\n",
    "\n",
    "However, we can easily define our own functions for _sample skewness_ and _sample kurtosis_ by using [`scipy.stats.moment`](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.moment.html) and [`numpy.std(z, ddof=1)`](https://docs.scipy.org/doc/numpy/reference/generated/numpy.std.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample skew of x = -0.028996564222850806\n"
     ]
    }
   ],
   "source": [
    "def skew(x, use_sample_sd=True):\n",
    "    \"\"\" Return the skew of x.\n",
    "    \n",
    "        Default is to use sample standard deviation on the denominator,\n",
    "        yielding sample skew. \n",
    "        \n",
    "        Specifying use_sample_sd=False is the same as using\n",
    "        scipy.stats.skew(x).\n",
    "    \"\"\"\n",
    "    ddof = 1 if use_sample_sd==True else 0\n",
    "    return moment(x, 3) / np.std(x, ddof=ddof)**3\n",
    "\n",
    "print('sample skew of x = {}'.format(skew(z)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample kurtosis of x = -0.03138467715866655\n"
     ]
    }
   ],
   "source": [
    "def kurt(x, use_sample_sd=True):\n",
    "    \"\"\" Return the excess kurtosis of x.\n",
    "    \n",
    "        Default is to use sample standard deviation on the denominator,\n",
    "        yielding sample kurtosis. \n",
    "        \n",
    "        Specifying use_sample_sd=False is the same as using\n",
    "        scipy.stats.kurtosis(x).\n",
    "    \"\"\"\n",
    "    ddof = 1 if use_sample_sd==True else 0\n",
    "    return moment(x, 4) / np.std(x, ddof=ddof)**4 - 3.0\n",
    "\n",
    "print('sample kurtosis of x = {}'.format(kurt(z)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Medians and modes\n",
    "\n",
    "To find the median of a continuous r.v. with CDF $F$, we need to solve the equation $F(x) = 1/2$ for $x$, which is equivalent to finding the root (zero) of the function $g$ given by $g(x) = F(x) − 1/2$. This can be done using uniroot in R. For example, let's find the median of the Expo(1) distribution. The code"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "g <- function(x) pexp(x) - 1/2\n",
    "uniroot(g,lower=0,upper=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "asks R to find a root of the desired function between 0 and 1. This returns an answer very close to the true answer of log(2) ≈ 0.693. Of course, in this case we can solve 1 − e −x = 1/2 directly without having to use numerical methods.\n",
    "\n",
    "&#x2623; 6.9.2. The uniroot command is useful but it only attempts to find one root (as the name suggests), and there is no guarantee that it will find a root.\n",
    "\n",
    "An easier way to find the median of the Expo(1) in R is to use qexp(1/2). The function qexp is the quantile function of the Expo(1) distribution, which means that qexp(p) is the value of x such that P(X ≤ x) = p for X ∼ Expo(1).\n",
    "\n",
    "For finding the mode of a continuous distribution, we can use the optimize function in R. For example, let’s find the mode of the Gamma(6, 1) distribution, which is an important distribution that we will introduce in the next chapter. Its PDF is proportional to x 5 e −x. Using calculus, we can find that the mode is at x = 5. Using R, we can find that the mode is very close to x = 5 as follows."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "h <- function(x) x^5*exp(-x)\n",
    "optimize(h,lower=0,upper=20,maximum=TRUE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we had wanted to minimize instead of maximize, we could have put maximum=FALSE.\n",
    "\n",
    "Next, let’s do a discrete example of median and mode. An interesting fact about the Bin(n, p) distribution is that if the mean np is an integer, then the median and mode are also np (even if the distribution is very skewed). To check this fact about the median for the Bin(50, 0.2) distribution, we can use the following code."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "n <- 50; p <- 0.2 \n",
    "which.max(pbinom(0:n,n,p)>=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The which.max function finds the location of the maximum of a vector, giving the index of the first occurrence of a maximum. Since TRUE is encoded as 1 and FALSE is encoded as 0, the first maximum in pbinom(0:n,n,p)>=0.5 is at the first value for which the CDF is at least 0.5. The output of the above code is 11, but we must be careful to avoid an off-by-one error: the index 11 corresponds to the median being 10, since we started evaluating the CDF at 0. Similarly, which.max(dbinom(0:n,n,p)) returns 11, showing that the mode is at 10.\n",
    "\n",
    "The sample median of a vector x of data can be found using median(x). But mode(x) does not give the sample mode of x (rather, it gives information about what type of object x is). To find the sample mode (or sample modes, in case there are ties), we can use the following function."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "datamode <- function(x) {\n",
    "    t <- table(x) \n",
    "    m <- max(t) \n",
    "    as.numeric(names(t[t==m])) \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dice simulation\n",
    "\n",
    "In the starred Section 6.7, we showed that in rolling 6 fair dice, the probability of a total of 18 is 3431/6 6. But the proof was complicated. If we only need an approximate answer, simulation is a much easier approach. And we already know how to do it! Here is the code for a million repetitions:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "r <- replicate(10^6,sum(sample(6,6,replace=TRUE)))\n",
    "sum(r==18)/10^6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our simulation this yielded 0.07346, which is very close to 3431/6 6 ≈ 0.07354."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "&copy; Blitzstein, Joseph K.; Hwang, Jessica. Introduction to Probability (Chapman & Hall/CRC Texts in Statistical Science)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
